{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== PARAMETERS =====\n",
      "Dataset =  mpg\n",
      "Defuzification method =  MOM\n",
      "Fuzzy distance =  D1\n",
      "Left spread = 0.2\n",
      "Right spread = 0.2\n",
      "Learning rate = 0.10\n",
      "Stump tree depth = 1\n",
      "============= Optimizm index = 0.5\n",
      "-- TRAIN: the best R^2 and RMSE values with according iteration number --\n",
      "maxM = 200\n",
      "maxR2 =     0.9096\n",
      "minRMSE =     2.3478\n",
      "-- TEST: the best R^2 and RMSE values with according iteration number --\n",
      "maxM = 54\n",
      "maxR2 =     0.8901\n",
      "minRMSE =     2.5458\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regression Algorithm V2\n",
    "# with target values as triangular fuzzy numbers\n",
    "# using different fuzzy distances and defuzzification methods\n",
    "# by Resmiye Nasiboglu and Efendi Nasibov\n",
    "# September, 2022\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as r\n",
    "import math\n",
    "from my_datasets import *\n",
    "from fuzzy_operations import *\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "\"\"\"\n",
    "fuzzyGBR - the main function with following parameters:\n",
    "dataset - is the dataset to handle (\"iris\", \"cars\", \"diabetes\", \"boston\", \"penguins\", \"planets\", \n",
    "        \"diamonds\", \"mpg\", \"tips\", taxis\")\n",
    "defuz_method - the defuzzification method: \n",
    "        \"MOM\" - mean of maxima, \n",
    "        \"COG\" - center of gravity, \n",
    "        \"WABL\" - weighted average based ol levels.\n",
    "max_left_spread - the maximum left side spread of the simulating target fuzzy numbers,\n",
    "max_right_spread - the maximum right side spread of the simulating target fuzzy numbers,\n",
    "distance - the fuzzy distance measures between the FNs A = (a[0],a[1],a[2]) and B = (b[0],b[1],b[2]):\n",
    "        D1(A, B) = max(abs(a[0]-b[0]),abs(a[1]-b[1]),abs(a[2]-b[2])) \n",
    "        D2(A, B) = abs(a[0]-b[0])+max(abs(a[1]-b[1]),abs(a[2]-b[2])) \n",
    "        D3(A, B) = abs(defuz(A)-defuz(B)) \n",
    "        D4(A, B) = abs(defuz(fuzSubtr(A,B))) \n",
    "boost_iterations - the number of boosting iterations,\n",
    "learning_rate - the learning rate of algorithm,\n",
    "tree_depth - the depth of the stump trees.\n",
    "\"\"\"\n",
    "\n",
    "def fuzzyGBR(dataset, defuz_method = \"MOM\", max_left_spread = 0.2, max_right_spread = 0.2, \n",
    "         distance = \"D4\", boost_iterations = 201, learning_rate = 0.1, tree_depth = 1):\n",
    "\n",
    "    print(\"===== PARAMETERS =====\")\n",
    "    print(\"Dataset = \", dataset)\n",
    "    print(\"Defuzification method = \", defuz_method)\n",
    "    print(\"Fuzzy distance = \", distance)\n",
    "    print(\"Left spread = %.1f\" % (max_left_spread))\n",
    "    print(\"Right spread = %.1f\" % (max_right_spread))\n",
    "    print(\"Learning rate = %.2f\" % (learning_rate))\n",
    "    print(\"Stump tree depth = %d\" % (tree_depth))\n",
    "\n",
    "    def c_cycle(c):\n",
    "        # c is the optimism parameter of the WABL method.\n",
    "        print(\"============= Optimizm index = %.1f\" % (c))\n",
    "        if dataset == \"iris\":\n",
    "            X_train,X_test,y_train,y_test = my_load_iris()\n",
    "        elif dataset == \"cars\":\n",
    "            X_train,X_test,y_train,y_test = my_load_car_prices()\n",
    "        elif dataset == \"diabetes\":\n",
    "            X_train,X_test,y_train,y_test = my_load_diabetes()\n",
    "        elif dataset == \"boston\":\n",
    "            X_train,X_test,y_train,y_test = my_load_boston()\n",
    "        elif dataset == \"penguins\":\n",
    "            X_train,X_test,y_train,y_test = my_load_penguins()\n",
    "        elif dataset == \"planets\":\n",
    "            X_train,X_test,y_train,y_test = my_load_planets()\n",
    "        elif dataset == \"diamonds\":\n",
    "            X_train,X_test,y_train,y_test = my_load_diamonds()\n",
    "        elif dataset == \"mpg\":\n",
    "            X_train,X_test,y_train,y_test = my_load_mpg()\n",
    "        elif dataset == \"tips\":\n",
    "            X_train,X_test,y_train,y_test = my_load_tips()\n",
    "        elif dataset == \"taxis\":\n",
    "            X_train,X_test,y_train,y_test = my_load_taxis()\n",
    "\n",
    "        r.seed(0) # initialization of the random generator.\n",
    "\n",
    "        # fuzzy number representation: A=(mode,l_width,r_width)\n",
    "\n",
    "        # in experiments the folowing forms of the FN should be used\n",
    "        #     l_max_width=0.2 and r_max_witth=0.2  (symmetrical case)\n",
    "        #     l_max_width=0.2 and r_max_witth=0.0  (left skewned case)\n",
    "        #     l_max_width=0.0 and r_max_witth=0.2  (right skewned case)\n",
    "\n",
    "        l_max_width = max_left_spread  # left max width of fuzzyness\n",
    "        r_max_width = max_right_spread  # right max width of fuzzyness\n",
    "\n",
    "        # reservation of empty fuzzy data \n",
    "        y_fuz_train=[[0,0,0] for _ in range(len(y_train))]\n",
    "        y_fuz_test=[[0,0,0] for _ in range(len(y_test))]\n",
    "\n",
    "        # generation of random fuzzy data \n",
    "        for i in range(len(y_train)):\n",
    "            y_fuz_train[i] = [y_train[i],y_train[i]*(l_max_width*r.random()),y_train[i]*(r_max_width*r.random())]\n",
    "        for i in range(len(y_test)):    \n",
    "            y_fuz_test[i] = [y_test[i],y_test[i]*(l_max_width*r.random()),y_test[i]*(r_max_width*r.random())]\n",
    "\n",
    "\n",
    "        # Standartization of the inputs\n",
    "\n",
    "        sc = MinMaxScaler()\n",
    "        X_train_std = sc.fit_transform(X_train)\n",
    "        X_test_std = sc.transform(X_test)\n",
    "\n",
    "        F=[[[0,0,0] for i in range(len(X_train))] for j in range(boost_iterations)]\n",
    "\n",
    "        # fuzzy average of the fuzzy train outputs. c is the optimism parameter of the WABL.\n",
    "        f_ave=fuzAve(y_fuz_train,c)\n",
    "\n",
    "        # F[i] is the fuzzy outputs of the model after i.th iteration\n",
    "        F[0]=[f_ave for _ in range(len(X_train))]\n",
    "\n",
    "        # gamma is the predicted fuzzy output (as a Fuzzy Number) according to the leaf \n",
    "        gamma=[[[0,0,0] for i in range(max_leaf)] for j in range(boost_iterations)]\n",
    "        trees=[]\n",
    "\n",
    "        # boosting iterations\n",
    "        for m in range(1,boost_iterations):    \n",
    "            rrr=[fuzSubtr(y_fuz_train[i],F[m-1][i],c) for i in range(len(y_fuz_train))]\n",
    "\n",
    "            # stump tree is constructed up to the defuzzified values of the FNs\n",
    "            r1=[defuz(defuz_method,rrr[i],c) for i in range(len(rrr))]\n",
    "\n",
    "            # constructing of the stump tree\n",
    "            tree = DecisionTreeRegressor(random_state=0,max_depth=tree_depth)\n",
    "            tree.fit(X_train_std, r1)\n",
    "            trees.append(tree)\n",
    "\n",
    "            # h is the list of the indices of the leafs\n",
    "            h=tree.apply(X_train_std)   \n",
    "\n",
    "            # h1 is the list of the distinct leaf indices \n",
    "            h1=list(set(h))\n",
    "\n",
    "            for l in range(len(h1)):\n",
    "                leaf_l=[j for j in range(len(r1)) if h[j]==h1[l]] \n",
    "                ss=[rrr[j] for j in leaf_l]\n",
    "                ss1=np.reshape(ss,(-1,3))\n",
    "                gamma[m][l]=fuzAve(ss1,c) #for each leaf node\n",
    "                for k in leaf_l:\n",
    "                    F[m][k]=fuzAdd(F[m-1][k],fuzMultBy(gamma[m][l],learning_rate,c),c) \n",
    "\n",
    "        # prediction\n",
    "        #print(\"----------- Train set R^2 and fuzRMSE -------------------\")\n",
    "        maxR2=-999999\n",
    "        minRMSE=-999999\n",
    "        maxM=-1\n",
    "\n",
    "        X1=X_train_std\n",
    "        fuzY=y_fuz_train\n",
    "\n",
    "        FM=F[0]  \n",
    "        ave=FM[0]  # average of train set\n",
    "\n",
    "        for m in range(1,boost_iterations):\n",
    "            h=trees[m-1].apply(X1)\n",
    "            h1=list(set(h))\n",
    "            for l in range(len(h1)):\n",
    "                leaf_l=[j for j in range(len(X_train)) if h[j]==h1[l]] \n",
    "                for k in leaf_l:\n",
    "                    FF=fuzAdd(FM[k],fuzMultBy(gamma[m][l],learning_rate,c),c)\n",
    "                    FM[k]=FF    #for each xi of each leaf node \n",
    "\n",
    "            R2=fuzR2(defuz_method,fuzY,FM,ave,c)\n",
    "            RMSE=fuzRMSE(defuz_method,fuzY,FM,c)\n",
    "            if R2>maxR2:\n",
    "                maxR2=R2\n",
    "                minRMSE=RMSE\n",
    "                maxM=m\n",
    "            if m%10==0:\n",
    "                pass #print(\"%3d %10.4f %10.4f\"%(m,R2,RMSE))\n",
    "\n",
    "        print(\"-- TRAIN: the best R^2 and RMSE values with according iteration number --\")\n",
    "        print(\"maxM =\",maxM)\n",
    "        print(\"maxR2 = %10.4f\"%(maxR2))\n",
    "        print(\"minRMSE = %10.4f\"%(minRMSE))\n",
    "\n",
    "        #print(\"----------- Test set R^2 and fuzRMSE -------------------\")\n",
    "        maxR2=-999999\n",
    "        minRMSE=-999999\n",
    "        maxM=-1\n",
    "\n",
    "        X1=X_test_std\n",
    "        fuzY=y_fuz_test\n",
    "        F=[[[0,0,0] for _ in range(len(X_test))] for i in range(boost_iterations)]\n",
    "\n",
    "        # initial average of all test set with ave(train)\n",
    "        F[0]=[fuzAve(y_fuz_train,c) for _ in range(len(X_test))] \n",
    "        FM=F[0] \n",
    "        #ave=FM[0]  # average of the train set\n",
    "\n",
    "        for m in range(1,boost_iterations):\n",
    "            h=trees[m-1].apply(X1)\n",
    "            h1=list(set(h))\n",
    "            for l in range(len(h1)):\n",
    "                leaf_l=[j for j in range(len(X1)) if h[j]==h1[l]] \n",
    "                for k in leaf_l:\n",
    "                    FF=fuzAdd(FM[k],fuzMultBy(gamma[m][l],learning_rate,c),c)\n",
    "                    FM[k]=FF    #for each xi of each leaf node \n",
    "\n",
    "            R2=fuzR2(defuz_method,fuzY,FM,ave,c)\n",
    "            RMSE=fuzRMSE(defuz_method,fuzY,FM,c)\n",
    "            if R2>maxR2:\n",
    "                maxR2=R2\n",
    "                minRMSE=RMSE\n",
    "                maxM=m\n",
    "            if m%10==0:\n",
    "                pass #print(\"%10.4f %10.4f\"%(R2,RMSE))   \n",
    "\n",
    "        print(\"-- TEST: the best R^2 and RMSE values with according iteration number --\")\n",
    "        print(\"maxM =\",maxM)\n",
    "        print(\"maxR2 = %10.4f\"%(maxR2))\n",
    "        print(\"minRMSE = %10.4f\"%(minRMSE))\n",
    "        \n",
    "\n",
    "    max_leaf=2**tree_depth  # maximum leaf number of the stump trees\n",
    "        \n",
    "    if defuz_method == \"WABL\":\n",
    "        cycles = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "    else:\n",
    "        cycles = [0.5]\n",
    "    for c in cycles:\n",
    "        c_cycle(c)\n",
    "\n",
    "# call the main function fuzzyGBR\n",
    "fuzzyGBR(dataset = \"mpg\", defuz_method = \"MOM\", max_left_spread = 0.2, max_right_spread = 0.2, \n",
    "         distance = \"D1\", boost_iterations = 201, learning_rate = 0.1, tree_depth = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
